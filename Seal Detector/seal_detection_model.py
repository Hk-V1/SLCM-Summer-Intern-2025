# -*- coding: utf-8 -*-
"""Seal Detection Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D52ohS4Sxlfie08m3REsrZ1_XGkhROq0
"""

import os
import glob
import shutil
import zipfile
import ipywidgets as widgets
from IPython.display import display, clear_output
from PIL import Image as PILImage
from google.colab import files
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Rescaling
from tensorflow.keras.models import load_model

"""UPLOADING AND EXTRACTING ZIP FILE"""

uploaded = files.upload()
for fname in uploaded:
    if fname.endswith(".zip"):
        with zipfile.ZipFile(fname, 'r') as zip_ref:
            zip_ref.extractall("all_images")
        print(f"Extracted {fname} into 'all_images/'")

"""FINDING IMAGES IN EXTRACTED FOLDER"""

img_dir = "all_images"
image_files = sorted(glob.glob(os.path.join(img_dir, "**", "*.jpg"), recursive=True) +
                     glob.glob(os.path.join(img_dir, "**", "*.png"), recursive=True) +
                     glob.glob(os.path.join(img_dir, "**", "*.jpeg"), recursive=True))

if len(image_files) == 0:
    raise Exception("No image files found in the ZIP. Please check folder structure!")

print(f"Found {len(image_files)} images for labeling.")

os.makedirs("blur_dataset/blurry", exist_ok=True)
os.makedirs("blur_dataset/not_blurry", exist_ok=True)
os.makedirs("seal_dataset/seal", exist_ok=True)
os.makedirs("seal_dataset/no_seal", exist_ok=True)

"""LABELING FUNCTIONS"""

current_index = 0

def show_image(idx):
    """Display current image"""
    if idx < len(image_files):
        img_path = image_files[idx]
        display(PILImage.open(img_path).resize((400, 300)))
        print(f"Image {idx+1}/{len(image_files)}: {os.path.basename(img_path)}")
        return True
    return False

def label_combined(blur_status, seal_status):
    """Label image for both blur and seal detection"""
    global current_index

    if current_index < len(image_files):
        src = image_files[current_index]

        blur_dst = os.path.join("blur_dataset", blur_status, os.path.basename(src))
        shutil.copy2(src, blur_dst)

        seal_dst = os.path.join("seal_dataset", seal_status, os.path.basename(src))
        shutil.copy2(src, seal_dst)

        print(f"Labeled as: {blur_status} + {seal_status}")

        current_index += 1
        clear_output(wait=True)

        if current_index < len(image_files):
            print("=== LABEL EACH IMAGE ===")
            print("Select the appropriate combination:")
            show_image(current_index)
            display(button_box)
        else:
            print("All images labeled successfully!")
            print(f"Blur dataset: blur_dataset/")
            print(f"Seal dataset: seal_dataset/")

"""CREATING INTERACTIVE BUTTONS"""

btn1 = widgets.Button(description="Blurry + Seal Present", button_style='warning', layout=widgets.Layout(width='200px'))
btn2 = widgets.Button(description="Blurry + No Seal", button_style='danger', layout=widgets.Layout(width='200px'))
btn3 = widgets.Button(description="Clear + Seal Present", button_style='success', layout=widgets.Layout(width='200px'))
btn4 = widgets.Button(description="Clear + No Seal", button_style='info', layout=widgets.Layout(width='200px'))

btn1.on_click(lambda x: label_combined("blurry", "seal"))
btn2.on_click(lambda x: label_combined("blurry", "no_seal"))
btn3.on_click(lambda x: label_combined("not_blurry", "seal"))
btn4.on_click(lambda x: label_combined("not_blurry", "no_seal"))

button_box = widgets.VBox([
    widgets.HTML("<b>Choose the correct label:</b>"),
    widgets.HBox([btn1, btn2]),
    widgets.HBox([btn3, btn4])
])

"""START LABELING"""

print("=== STARTING IMAGE LABELING ===")
print("Label each image with both blur status and seal presence")
print("Click the appropriate button for each image")
print()

current_index = 0
if show_image(current_index):
    display(button_box)

print("\n" + "="*60)
print("Initiating Model Training Phase...")
print("="*60)

def train_models():
    """Trains both blur and seal detection models with optional improvements."""

    USE_DATA_AUGMENTATION = True
    USE_TRANSFER_LEARNING = True

    data_augmentation = tf.keras.Sequential([
        layers.RandomFlip("horizontal_and_vertical"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1, 0.1),
        layers.RandomContrast(0.1),
    ])

    def create_custom_cnn_model():
        """Defines a custom Convolutional Neural Network architecture."""
        model = keras.Sequential([
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Flatten(),
            layers.Dropout(0.5),
            layers.Dense(512, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(1, activation='sigmoid')
        ])
        return model

    def create_transfer_learning_model():
        """
        Defines a model using a pre-trained MobileNetV2 base for transfer learning.
        This is very effective for small datasets as it leverages features learned
        from a large dataset (ImageNet).
        """
        base_model = tf.keras.applications.MobileNetV2(
            input_shape=(128,128,3),
            include_top=False,
            weights='imagenet'
        )
        base_model.trainable = False
        model = keras.Sequential([
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dropout(0.3),
            layers.Dense(1, activation='sigmoid')
        ])
        return model

    os.makedirs("models", exist_ok=True)

    normalization_layer = Rescaling(1./255)

    print("\nTraining blur detection model...")
    try:
        blur_train_ds = tf.keras.utils.image_dataset_from_directory(
            "blur_dataset",
            validation_split=0.2,
            subset="training",
            seed=123,
            image_size=(128, 128),
            batch_size=16
        )
        blur_val_ds = tf.keras.utils.image_dataset_from_directory(
            "blur_dataset",
            validation_split=0.2,
            subset="validation",
            seed=123,
            image_size=(128, 128),
            batch_size=16
        )

        if USE_DATA_AUGMENTATION:
            print("Applying Data Augmentation to blur training dataset.")
            blur_train_ds = blur_train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))

        blur_train_ds = blur_train_ds.map(lambda x, y: (normalization_layer(x), y))
        blur_val_ds = blur_val_ds.map(lambda x, y: (normalization_layer(x), y))

        if USE_TRANSFER_LEARNING:
            print("Using Transfer Learning (MobileNetV2) for blur model.")
            blur_model = create_transfer_learning_model()
        else:
            print("Using Custom CNN for blur model.")
            blur_model = create_custom_cnn_model()

        blur_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

        blur_model.fit(
            blur_train_ds,
            validation_data=blur_val_ds,
            epochs=20,
            callbacks=[keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)],
            verbose=1
        )

        blur_model.save("models/blur_detector.h5")
        print("Blur detection model saved to models/blur_detector.h5!")

    except Exception as e:
        print(f"Error training blur model: {type(e).__name__}: {e}")
        print("Please ensure your 'blur_dataset' has 'blurry' and 'not_blurry' subdirectories with images.")


    print("\nTraining seal detection model...")
    try:
        seal_train_ds = tf.keras.utils.image_dataset_from_directory(
            "seal_dataset",
            validation_split=0.2,
            subset="training",
            seed=123,
            image_size=(128, 128),
            batch_size=16
        )
        seal_val_ds = tf.keras.utils.image_dataset_from_directory(
            "seal_dataset",
            validation_split=0.2,
            subset="validation",
            seed=123,
            image_size=(128, 128),
            batch_size=16
        )

        if USE_DATA_AUGMENTATION:
            print("Applying Data Augmentation to seal training dataset.")
            seal_train_ds = seal_train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))

        seal_train_ds = seal_train_ds.map(lambda x, y: (normalization_layer(x), y))
        seal_val_ds = seal_val_ds.map(lambda x, y: (normalization_layer(x), y))

        if USE_TRANSFER_LEARNING:
            print("Using Transfer Learning (MobileNetV2) for seal model.")
            seal_model = create_transfer_learning_model()
        else:
            print("Using Custom CNN for seal model.")
            seal_model = create_custom_cnn_model()

        seal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

        seal_model.fit(
            seal_train_ds,
            validation_data=seal_val_ds,
            epochs=20,
            callbacks=[keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)],
            verbose=1
        )

        seal_model.save("models/seal_detector.h5")
        print("Seal detection model saved to models/seal_detector.h5!")

    except Exception as e:
        print(f"Error training seal model: {type(e).__name__}: {e}")
        print("Please ensure your 'seal_dataset' has 'seal' and 'no_seal' subdirectories with images.")

    print("\nModel training complete!")

train_models()

"""PREDICTION ON NEW IMAGE"""

print("\nPlease upload an image for prediction:")
uploaded = files.upload()
image_path = list(uploaded.keys())[0]

blur_model = load_model("models/blur_detector.h5")
seal_model = load_model("models/seal_detector.h5")

def preprocess_image(path):
    img = PILImage.open(path).convert("RGB")
    img = img.resize((128, 128))
    img_array = np.array(img) / 255.0  # normalize
    img_array = np.expand_dims(img_array, axis=0)  # batch dimension
    return img_array, img

image_array, display_image = preprocess_image(image_path)

blur_pred = blur_model.predict(image_array)[0][0]
seal_pred = seal_model.predict(image_array)[0][0]

blur_label = "Blurry" if blur_pred > 0.5 else "Usable"
seal_label = "Seal Detected" if seal_pred > 0.5 else "No Seal"

import matplotlib.pyplot as plt
plt.imshow(display_image)
plt.axis("off")
plt.title(f"{blur_label} | {seal_label}")
plt.show()

print(f"Blur score: {blur_pred:.4f} -> {blur_label}")
print(f"Seal score: {seal_pred:.4f} -> {seal_label}")

import tensorflow as tf

blur_model_path = "models/blur_detector.h5"
seal_model_path = "models/seal_detector.h5"

blur_model = tf.keras.models.load_model(blur_model_path)
seal_model = tf.keras.models.load_model(seal_model_path)

blur_converter = tf.lite.TFLiteConverter.from_keras_model(blur_model)
blur_tflite_model = blur_converter.convert()
with open("models/blur_detector.tflite", "wb") as f:
    f.write(blur_tflite_model)
print("blur_detector.tflite saved!")

seal_converter = tf.lite.TFLiteConverter.from_keras_model(seal_model)
seal_tflite_model = seal_converter.convert()
with open("models/seal_detector.tflite", "wb") as f:
    f.write(seal_tflite_model)
print("seal_detector.tflite saved!")

